{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们使用一个脑部病变数据集作为范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (4.66.6)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kaggle) (3.10)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=25ae1fbe558fa7c7b5cb29d66bf7825218d64560626d63a049dddf28de6b6e39\n",
      "  Stored in directory: /home/zeus/.cache/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "Successfully built kaggle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3\n",
      "Dataset URL: https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading lgg-mri-segmentation.zip to /teamspace/studios/this_studio\n",
      " 39%|███████████████▊                         | 275M/714M [00:02<00:02, 184MB/s]"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "!kaggle datasets download aryashah2k/breast-ultrasound-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open lgg-mri-segmentation.zip, lgg-mri-segmentation.zip.zip or lgg-mri-segmentation.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip breast-ultrasound-images-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def generate_metadata_csv(dataset_path, output_csv):\n",
    "    # Define the headers for the CSV file\n",
    "    headers = ['image_path', 'mask_path']\n",
    "\n",
    "    # Prepare a list to store metadata\n",
    "    metadata = []\n",
    "\n",
    "    # Iterate through each subfolder (benign, malignant)\n",
    "    for category in ['benign', 'malignant']:\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "\n",
    "        # Iterate through all files in the category folder\n",
    "        for file_name in os.listdir(category_path):\n",
    "            if '_mask' not in file_name and file_name.endswith('.png'):\n",
    "                # Define the image and mask file paths\n",
    "                image_path = os.path.join(category_path, file_name)\n",
    "                mask_name = file_name.replace('.png', '_mask.png')\n",
    "                mask_path = os.path.join(category_path, mask_name)\n",
    "\n",
    "                # Append the paths to metadata if the mask exists\n",
    "                if os.path.exists(mask_path):\n",
    "                    metadata.append([image_path, mask_path])\n",
    "\n",
    "    # Write the metadata to the CSV file\n",
    "    with open(output_csv, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(metadata)\n",
    "\n",
    "# Specify the dataset directory and output CSV file\n",
    "dataset_dir = 'Dataset_BUSI_with_GT'\n",
    "output_csv_path = 'Dataset_BUSI_with_GT/metadata.csv'\n",
    "\n",
    "# Generate the metadata CSV\n",
    "generate_metadata_csv(dataset_dir, output_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
