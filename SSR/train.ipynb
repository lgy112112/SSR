{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 256, 256]) torch.Size([8, 1, 256, 256])\n",
      "torch.Size([8, 1, 256, 256]) torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from SSR.dataset import BrainLesionDataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 定义图像和掩膜的预处理与增强\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 创建完整数据集实例\n",
    "csv_file = 'Dataset_BUSI_with_GT/metadata.csv'\n",
    "full_dataset = BrainLesionDataset(csv_file=csv_file, transform=base_transform)\n",
    "\n",
    "# 将数据集划分为训练集、验证集和测试集\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 定义批量大小\n",
    "batch_size = 8  # 可根据硬件资源调整批量大小\n",
    "\n",
    "# 创建DataLoader，用于批量加载训练、验证和测试数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "# 示例：检查训练集中的图像和掩膜大小\n",
    "for images, masks, image_paths, mask_paths in train_loader:\n",
    "    print(images.shape, masks.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at Step 9976\n",
      "----------------------------------------\n",
      "Starting training epoch...\n",
      "Batch 1/57 - Loss: 0.7068, Dice: 0.9676, Low confidence samples: 0\n",
      "Batch 2/57 - Loss: 0.8291, Dice: 0.9275, Low confidence samples: 1\n",
      "Batch 3/57 - Loss: 0.6761, Dice: 0.9210, Low confidence samples: 0\n",
      "Batch 4/57 - Loss: 0.6891, Dice: 0.9353, Low confidence samples: 0\n",
      "Batch 5/57 - Loss: 0.6905, Dice: 0.9436, Low confidence samples: 0\n",
      "Batch 6/57 - Loss: 0.6649, Dice: 0.9497, Low confidence samples: 0\n",
      "Batch 7/57 - Loss: 0.7469, Dice: 0.9506, Low confidence samples: 0\n",
      "Batch 8/57 - Loss: 0.6846, Dice: 0.9506, Low confidence samples: 0\n",
      "Batch 9/57 - Loss: 0.6671, Dice: 0.9529, Low confidence samples: 0\n",
      "Batch 10/57 - Loss: 0.6885, Dice: 0.9549, Low confidence samples: 0\n",
      "Batch 11/57 - Loss: 0.6653, Dice: 0.9566, Low confidence samples: 0\n",
      "Batch 12/57 - Loss: 0.7075, Dice: 0.9580, Low confidence samples: 0\n",
      "Batch 13/57 - Loss: 0.6890, Dice: 0.9588, Low confidence samples: 0\n",
      "Batch 14/57 - Loss: 0.6772, Dice: 0.9600, Low confidence samples: 0\n",
      "Batch 15/57 - Loss: 0.7182, Dice: 0.9607, Low confidence samples: 0\n",
      "Batch 16/57 - Loss: 0.6986, Dice: 0.9609, Low confidence samples: 0\n",
      "Batch 17/57 - Loss: 0.6923, Dice: 0.9611, Low confidence samples: 0\n",
      "Batch 18/57 - Loss: 0.6889, Dice: 0.9614, Low confidence samples: 0\n",
      "Batch 19/57 - Loss: 0.6781, Dice: 0.9622, Low confidence samples: 0\n",
      "Batch 20/57 - Loss: 0.6827, Dice: 0.9629, Low confidence samples: 0\n",
      "Batch 21/57 - Loss: 0.6897, Dice: 0.9634, Low confidence samples: 0\n",
      "Batch 22/57 - Loss: 0.6922, Dice: 0.9639, Low confidence samples: 0\n",
      "Batch 23/57 - Loss: 0.7044, Dice: 0.9643, Low confidence samples: 0\n",
      "Batch 24/57 - Loss: 0.6906, Dice: 0.9647, Low confidence samples: 0\n",
      "Batch 25/57 - Loss: 0.6984, Dice: 0.9651, Low confidence samples: 0\n",
      "Batch 26/57 - Loss: 0.7346, Dice: 0.9649, Low confidence samples: 0\n",
      "Batch 27/57 - Loss: 0.6731, Dice: 0.9647, Low confidence samples: 0\n",
      "Batch 28/57 - Loss: 0.7058, Dice: 0.9649, Low confidence samples: 0\n",
      "Batch 29/57 - Loss: 0.7082, Dice: 0.9649, Low confidence samples: 0\n",
      "Batch 30/57 - Loss: 0.7153, Dice: 0.9649, Low confidence samples: 0\n",
      "Batch 31/57 - Loss: 0.7484, Dice: 0.9642, Low confidence samples: 0\n",
      "Batch 32/57 - Loss: 0.6956, Dice: 0.9637, Low confidence samples: 0\n",
      "Batch 33/57 - Loss: 0.6853, Dice: 0.9640, Low confidence samples: 0\n",
      "Batch 34/57 - Loss: 0.7049, Dice: 0.9642, Low confidence samples: 0\n",
      "Batch 35/57 - Loss: 0.6937, Dice: 0.9644, Low confidence samples: 0\n",
      "Batch 36/57 - Loss: 0.6857, Dice: 0.9645, Low confidence samples: 0\n",
      "Batch 37/57 - Loss: 0.6684, Dice: 0.9647, Low confidence samples: 0\n",
      "Batch 38/57 - Loss: 0.6938, Dice: 0.9649, Low confidence samples: 0\n",
      "Batch 39/57 - Loss: 0.7034, Dice: 0.9648, Low confidence samples: 0\n",
      "Batch 40/57 - Loss: 0.7344, Dice: 0.9644, Low confidence samples: 0\n",
      "Batch 41/57 - Loss: 0.6750, Dice: 0.9641, Low confidence samples: 0\n",
      "Batch 42/57 - Loss: 0.7010, Dice: 0.9643, Low confidence samples: 0\n",
      "Batch 43/57 - Loss: 0.6919, Dice: 0.9644, Low confidence samples: 0\n",
      "Batch 44/57 - Loss: 0.6761, Dice: 0.9645, Low confidence samples: 0\n",
      "Batch 45/57 - Loss: 0.6648, Dice: 0.9648, Low confidence samples: 0\n",
      "Batch 46/57 - Loss: 0.8266, Dice: 0.9636, Low confidence samples: 1\n",
      "Batch 47/57 - Loss: 0.7167, Dice: 0.9624, Low confidence samples: 0\n",
      "Batch 48/57 - Loss: 0.6932, Dice: 0.9625, Low confidence samples: 0\n",
      "Batch 49/57 - Loss: 0.6902, Dice: 0.9626, Low confidence samples: 0\n",
      "Batch 50/57 - Loss: 0.6727, Dice: 0.9628, Low confidence samples: 0\n",
      "Batch 51/57 - Loss: 0.6762, Dice: 0.9631, Low confidence samples: 0\n",
      "Batch 52/57 - Loss: 0.6889, Dice: 0.9633, Low confidence samples: 0\n",
      "Batch 53/57 - Loss: 0.6850, Dice: 0.9635, Low confidence samples: 0\n",
      "Batch 54/57 - Loss: 0.6993, Dice: 0.9637, Low confidence samples: 0\n",
      "Batch 55/57 - Loss: 0.6737, Dice: 0.9639, Low confidence samples: 0\n",
      "Batch 56/57 - Loss: 0.7103, Dice: 0.9640, Low confidence samples: 0\n",
      "Batch 57/57 - Loss: 0.6878, Dice: 0.9640, Low confidence samples: 0\n",
      "Training epoch completed - Average Loss: 0.6982, Average Dice: 0.9640\n",
      "Training Loss: 0.6982, Training Dice: 0.9640\n",
      "Current steps: 10032/10000\n",
      "Starting validation epoch...\n",
      "Validation Batch 1/13 - Loss: 0.7868, Dice: 0.8875\n",
      "Validation Batch 2/13 - Loss: 0.9349, Dice: 0.8240\n",
      "Validation Batch 3/13 - Loss: 0.8782, Dice: 0.8172\n",
      "Validation Batch 4/13 - Loss: 0.8573, Dice: 0.8175\n",
      "Validation Batch 5/13 - Loss: 1.1710, Dice: 0.7639\n",
      "Validation Batch 6/13 - Loss: 0.8846, Dice: 0.7672\n",
      "Validation Batch 7/13 - Loss: 0.8638, Dice: 0.7743\n",
      "Validation Batch 8/13 - Loss: 1.0104, Dice: 0.7612\n",
      "Validation Batch 9/13 - Loss: 0.8606, Dice: 0.7673\n",
      "Validation Batch 10/13 - Loss: 0.9037, Dice: 0.7676\n",
      "Validation Batch 11/13 - Loss: 0.7735, Dice: 0.7796\n",
      "Validation Batch 12/13 - Loss: 0.9248, Dice: 0.7773\n",
      "Validation Batch 13/13 - Loss: 0.7769, Dice: 0.7778\n",
      "Validation epoch completed - Average Loss: 0.8943, Average Dice Score: 0.7778\n",
      "Validation Loss: 0.8943, Validation Dice Score: 0.7778\n",
      "Reached total training steps. Ending training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 14:43:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.2.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/11/12 14:44:00 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.17.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torchvision==0.17.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/11/12 14:44:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.networks.nets import BasicUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from SSR.pipeline import train_epoch, val_epoch\n",
    "import mlflow\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 配置设备、模型和损失函数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BasicUNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    features=(32, 32, 64, 128, 256, 32),\n",
    "    spatial_dims=2,\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = DiceCELoss()\n",
    "\n",
    "# 定义训练参数\n",
    "total_steps = 10000  # 固定的训练步数\n",
    "current_steps = 0    # 当前步数计数\n",
    "confidence_threshold = 0.6  # 低信心阈值\n",
    "\n",
    "# 启动 MLflow 实验\n",
    "mlflow.set_experiment(\"Breast Ultrasound Segmentation\")  # 设置实验名称\n",
    "\n",
    "with mlflow.start_run(run_name=\"BasicUNet Baseline\"):\n",
    "    # 记录参数\n",
    "    mlflow.log_param(\"learning_rate\", 0.001)\n",
    "    mlflow.log_param(\"total_steps\", total_steps)\n",
    "\n",
    "    epoch = 0\n",
    "    while current_steps < total_steps:\n",
    "        print(f\"\\nStarting at Step {current_steps + 1}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 1. 训练阶段\n",
    "        train_loss, train_dice, _ = train_epoch(\n",
    "            model=model, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        \n",
    "        # 计算当前训练步数\n",
    "        current_steps += len(train_loader)  # 每个 train_loader 的长度即为一个 epoch 的步数\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Training Dice: {train_dice:.4f}\")\n",
    "        print(f\"Current steps: {current_steps}/{total_steps}\")\n",
    "\n",
    "        # 2. 验证阶段\n",
    "        val_loss, val_dice = val_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device\n",
    "        )\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Dice Score: {val_dice:.4f}\")\n",
    "\n",
    "        # 记录指标\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_dice\", train_dice, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_dice\", val_dice, step=epoch)\n",
    "\n",
    "        # 若达到总步数限制，则停止训练\n",
    "        if current_steps >= total_steps:\n",
    "            print(\"Reached total training steps. Ending training.\")\n",
    "            break\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        clear_output()\n",
    "        epoch += 1\n",
    "\n",
    "    # 保存模型\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 15:04:49 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.2.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 15:04:56 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.17.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torchvision==0.17.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/11/12 15:04:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.networks.nets import BasicUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from IPython.display import clear_output\n",
    "from SSR.pipeline import train_epoch, val_epoch, review_epoch\n",
    "from SSR.dataset import ReviewDataset\n",
    "import mlflow\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# 定义复习阶段的数据增强变换\n",
    "review_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 配置设备、模型和损失函数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BasicUNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    features=(32, 32, 64, 128, 256, 32),\n",
    "    spatial_dims=2,\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = DiceCELoss()\n",
    "\n",
    "# 定义实验参数\n",
    "total_steps = 10000  # 固定的训练总步数\n",
    "current_steps = 0    # 当前训练的步数计数\n",
    "review_epochs = 4   # 每轮复习的次数\n",
    "confidence_threshold = 0.7  # 低信心阈值\n",
    "\n",
    "# 启动 MLflow 实验\n",
    "mlflow.set_experiment(\"Breast Ultrasound Segmentation with Review\")  # 设置实验名称\n",
    "\n",
    "with mlflow.start_run(run_name=\"BasicUNet with Review Epoch\"):\n",
    "    # 记录参数\n",
    "    mlflow.log_param(\"learning_rate\", 0.001)\n",
    "    mlflow.log_param(\"total_steps\", total_steps)\n",
    "    mlflow.log_param(\"review_epochs_per_round\", review_epochs)\n",
    "    mlflow.log_param(\"confidence_threshold\", confidence_threshold)\n",
    "\n",
    "    epoch = 0\n",
    "    while current_steps < total_steps:\n",
    "        print(f\"\\nStarting at Step {current_steps + 1}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 1. 训练阶段\n",
    "        train_loss, train_dice, low_confidence_samples = train_epoch(\n",
    "            model=model, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Training Dice: {train_dice:.4f}\")\n",
    "        \n",
    "        # 累计步数\n",
    "        current_steps += len(train_loader)\n",
    "        print(f\"Current steps: {current_steps}/{total_steps}\")\n",
    "        \n",
    "        # 记录训练指标\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_dice\", train_dice, step=epoch)\n",
    "\n",
    "        # 检查是否达到总步数限制\n",
    "        if current_steps >= total_steps:\n",
    "            print(\"Reached total training steps. Ending training.\")\n",
    "            break\n",
    "\n",
    "        # 2. 验证阶段\n",
    "        val_loss, val_dice = val_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device\n",
    "        )\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Dice Score: {val_dice:.4f}\")\n",
    "        \n",
    "        # 记录验证指标\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_dice\", val_dice, step=epoch)\n",
    "\n",
    "        # 3. 复习阶段（仅当有低信心样本且未达到步数限制时）\n",
    "        if low_confidence_samples and current_steps < total_steps:\n",
    "            print(f\"{len(low_confidence_samples)} low confidence samples collected for review.\")\n",
    "            review_dataset = ReviewDataset(samples=low_confidence_samples, transform=review_transform)\n",
    "            review_loader = DataLoader(review_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "            # 执行复习过程\n",
    "            for review_epoch_num in range(review_epochs):\n",
    "                if current_steps >= total_steps:\n",
    "                    break  # 若达到总步数限制，则停止复习阶段\n",
    "                print(f\"\\nReview Epoch {review_epoch_num + 1}/{review_epochs}\")\n",
    "                \n",
    "                review_loss, review_dice = review_epoch(\n",
    "                    model=model, \n",
    "                    review_loader=review_loader, \n",
    "                    optimizer=optimizer, \n",
    "                    criterion=criterion, \n",
    "                    device=device\n",
    "                )\n",
    "                print(f\"Review Loss: {review_loss:.4f}, Review Dice: {review_dice:.4f}\")\n",
    "                \n",
    "                # 累计复习步数\n",
    "                current_steps += len(review_loader)\n",
    "                print(f\"Current steps (including review): {current_steps}/{total_steps}\")\n",
    "\n",
    "                # 记录复习阶段的指标\n",
    "                mlflow.log_metric(\"review_loss\", review_loss, step=epoch * review_epochs + review_epoch_num)\n",
    "                mlflow.log_metric(\"review_dice\", review_dice, step=epoch * review_epochs + review_epoch_num)\n",
    "\n",
    "            # 复习后的验证阶段\n",
    "            if current_steps < total_steps:\n",
    "                review_val_loss, review_val_dice = val_epoch(\n",
    "                    model=model, \n",
    "                    val_loader=val_loader, \n",
    "                    criterion=criterion, \n",
    "                    device=device\n",
    "                )\n",
    "                print(f\"Post-Review Validation Loss: {review_val_loss:.4f}, Post-Review Validation Dice Score: {review_val_dice:.4f}\")\n",
    "                \n",
    "                # 记录复习后的验证指标\n",
    "                mlflow.log_metric(\"post_review_val_loss\", review_val_loss, step=epoch)\n",
    "                mlflow.log_metric(\"post_review_val_dice\", review_val_dice, step=epoch)\n",
    "        else:\n",
    "            print(\"Skipping review epoch as no low confidence samples were found.\")\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        clear_output()\n",
    "        epoch += 1\n",
    "\n",
    "    # 保存模型\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'low_confidence_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 使用示例\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m visualize_random_sample(\u001b[43mlow_confidence_samples\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'low_confidence_samples' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_random_sample(low_confidence_samples):\n",
    "    # 随机抽取一个样本\n",
    "    print(f\"Length: {len(low_confidence_samples)}\")\n",
    "    sample = random.choice(low_confidence_samples)\n",
    "    image_path = sample['image_path']\n",
    "    mask_path = sample['mask_path']\n",
    "\n",
    "    # 打开图像和掩膜\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "    # 显示图像和掩膜\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(image, cmap='gray')\n",
    "    axs[0].set_title('Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(mask, cmap='gray')\n",
    "    axs[1].set_title('Mask')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 使用示例\n",
    "visualize_random_sample(low_confidence_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
